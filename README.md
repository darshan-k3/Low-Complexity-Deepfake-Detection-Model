# Low Complexity Deepfake Detection Comparative Study

Synthetic media generation poses an existential threat to the trust people place in content online. 
It can be used to disseminate disinformation, damage reputations of celebrities or manipulate political narratives.
As a result, ongoing efforts to detect such forgeries, also known as "deepfakes" has become increasingly important.
We perform a novel comparative study on state-of-the-art multimodal models on an ethnically diverse and challenging benchmark dataset that encompasses a variety of video and audio tampering techniques to seek out models that classify to a high degree of accuracy and are efficient.
After comparing multimodal models with their unimodal counterparts, we demonstrate that multimodal models outperform unimodal models and do not compromise on complexity to a significant degree.
Out of the set of models compared, clusters of groups emerge that experimentally and theoretically to satisfy the complexity performance trade-off the best. 
